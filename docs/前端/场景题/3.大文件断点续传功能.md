# 3.大文件断点续传功能

## 各个版本的上传组件

1. 原生+axios.post
2. 断点续传，秒传判断，类型判断
3. web-worker，时间切片，抽样 hash
4. 异步并发数控制，切片报错重试
5. 慢启动，碎片清理，上传暂停

### 断点续传+秒传+进度条

#### 文件切片

- 文件 File 对象是 Blob 对象的子类，Blob 对象包含一个重要的方法 slice，通过这个方法，我们就可以对二进制文件进行拆分。

#### 使用 md5 计算 hash 值

1. 可以抽样 hash

   1. 我们将 file 解析为二进制 buffer 数据,

   2. 抽取文件头尾 2mb, 中间的部分每隔 2mb 抽取 2kb

   3. 将这些片段组合成新的 buffer,进行 md5 计算。

2. 使用 worker 或者 类似 Fiber 的 requestIdleCallback 计算

3. 使用 worker 计算文件切片 hash 值, 通过 postMessage 向主线程发送 hash 值

#### 秒传

1. 前端：根据后端的回应，判断文件是否已经传输过
2. 后端：根据文件 hash 创建文件夹，保存文件切片，如: 文件夹 xxx 下 的文件 xxx_01, xxx_02

#### 进度条

1. xmlHTTPRequest 回调中监听
2. 手动计算上传的片段

#### 类型判断

1. 通过后缀判断
2. 通过文件转为二进制 blob 的前几个字节判断。（有现有库）

#### 异步并发数控制，和并发重试

1. 封装 100 个请求并发池
2. 使用 promise.race，在 then 中递归传入下一个请求
3. 使用 catch 捕获错误，给每个任务设置重试次数，超过 3 次就 reject，停止传输。
4. 维护一个请求列表，存放未收到响应的请求，暂停时调用`xhr`对象的 `abort`方法。

#### 慢启动

1. 参考 TCP 慢启动策略
2. 设置一个初始大小，动态调整下个切片大小，确保文件切片的大小和当前网速匹配
3. 时间统计、size 值

#### 文件合并（三种方案）

1.  前端发送完切片，发送合并请求，后端再合并。
2.  后端纪律切片数据，自动完成合并
3.  创建源文件大小相同文件，根据切片起始位置直接将切片写入对应位置。

#### 文件碎片清理

1. 可能用户传到一半就不传了，可以在后端使用定时任务清理不需要的碎片文件
